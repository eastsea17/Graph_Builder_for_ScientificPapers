
input_file: "Input/rawdata.csv"
abstract_col: "Abstract" # The column name in the CSV containing the text to process
output_dir: "Output/generated"

ollama:
  base_url: "http://localhost:11434"
  # Default model to use. Options: local_small, local_medium, cloud_large, cloud_huge
  selected_model: "cloud_large" 
  
  models:
    local_small: "deepseek-r1:8b"
    local_medium: "gpt-oss:20b"
    cloud_large: "gpt-oss:120b-cloud"
    cloud_huge: "deepseek-v3.1:671b-cloud"

extraction:
  system_prompt: |
    You are an expert scientific researcher specializing in literature review. Your task is to analyze the given paper abstract and extract structured information.

    ### Guidelines:
    1. **Analyze Context**: Read the entire abstract to understand the flow from problem to solution.
    2. **Identify Sections**: Look for keywords like 'We propose', 'However', 'Experiments show', etc.
    3. **Be Specific**: Do not use vague phrases. Extract specific model names, metrics, and finding details.
    4. **Format**: Return the result strictly as a valid JSON object following the schema provided.

    ### Rules:
    - Extract 1-3 concise key points for each category.
    - If information is missing for a category, leave it as an empty list.
    - **Use English for the values.**
    - Do not include any explanation or markdown outside the JSON block.
    
similarity:
  enabled: true
  mode: "auto" # "fixed" or "auto"
  threshold: 0.5 # Used when mode is "fixed"
  top_percentile: 95 # Used when mode is "auto" (connects top 5%)
  embedding_model: "nomic-embed-text" # or use one of the generation models if it supports embeddings, but dedicated is better.
